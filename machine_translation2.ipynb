{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDTfjSinXfWn",
        "outputId": "07eff937-df43-428a-fa0a-4ab61b080e7c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXUNH3r8YDRc",
        "outputId": "89ba916c-d5c7-4aed-f8dc-0bd3d8dd0f1b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "R0YdYHeAVwxv"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "import evaluate\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"bentrevett/multi30k\", split={\"train\": \"train\", \"validation\": \"validation\", \"test\": \"test\"})"
      ],
      "metadata": {
        "id": "ctOhM4O0Wc1o"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianTokenizer, MarianConfig, MarianMTModel\n",
        "\n",
        "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqrQHwP-WgQv",
        "outputId": "f10fe52c-0aa3-4ae0-e3e4-8b1f315ad148"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = MarianConfig(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    encoder_layers=6,\n",
        "    decoder_layers=6,\n",
        "    encoder_attention_heads=8,\n",
        "    decoder_attention_heads=8,\n",
        "    d_model=512,\n",
        "    decoder_ffn_dim=2048,\n",
        "    encoder_ffn_dim=2048,\n",
        "    activation_function=\"relu\",\n",
        "    dropout=0.1\n",
        ")\n",
        "model = MarianMTModel(config)\n",
        "\n",
        "source_lang = \"en\"\n",
        "target_lang = \"de\""
      ],
      "metadata": {
        "id": "xnLoECqOWkxk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(batch):\n",
        "    model_inputs = tokenizer(batch[\"en\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"de\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    labels[\"input_ids\"] = [\n",
        "        [(label if label != tokenizer.pad_token_id else -100) for label in label_seq]\n",
        "        for label_seq in labels[\"input_ids\"]\n",
        "    ]\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "4BBBqy5sW84F"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(preprocess, batched=True)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")"
      ],
      "metadata": {
        "id": "2ykm78VHW_zs"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    filtered_preds, filtered_labels = [], []\n",
        "    for pred, label in zip(decoded_preds, decoded_labels):\n",
        "        if label.strip():\n",
        "            filtered_preds.append(pred)\n",
        "            filtered_labels.append([label])\n",
        "\n",
        "    if len(filtered_labels) == 0:\n",
        "        return {\"bleu\": 0.0}\n",
        "\n",
        "    return bleu.compute(predictions=filtered_preds, references=filtered_labels)"
      ],
      "metadata": {
        "id": "NYqXb6iLXBa0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./mt-checkpoint\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=20,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "0WiVzFXaX28d"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xT2wlYBXXGVs",
        "outputId": "fac56edc-c91f-40dc-a04b-dde603b9f70a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2377121217.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36260' max='36260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36260/36260 58:26, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Precisions</th>\n",
              "      <th>Brevity Penalty</th>\n",
              "      <th>Length Ratio</th>\n",
              "      <th>Translation Length</th>\n",
              "      <th>Reference Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.070900</td>\n",
              "      <td>4.754417</td>\n",
              "      <td>0.021373</td>\n",
              "      <td>[0.32896825396825397, 0.061989852195014336, 0.011177347242921014, 0.0026996305768684286]</td>\n",
              "      <td>0.763122</td>\n",
              "      <td>0.787193</td>\n",
              "      <td>10080</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.264800</td>\n",
              "      <td>4.211071</td>\n",
              "      <td>0.047791</td>\n",
              "      <td>[0.3178559791463017, 0.08035872846741254, 0.026053864168618268, 0.009313406974225688]</td>\n",
              "      <td>0.957823</td>\n",
              "      <td>0.958688</td>\n",
              "      <td>12276</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.944800</td>\n",
              "      <td>3.894757</td>\n",
              "      <td>0.064402</td>\n",
              "      <td>[0.34257522629046727, 0.10027558005156013, 0.039081582804103565, 0.015291183168853703]</td>\n",
              "      <td>0.956765</td>\n",
              "      <td>0.957673</td>\n",
              "      <td>12263</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.575300</td>\n",
              "      <td>3.565189</td>\n",
              "      <td>0.081366</td>\n",
              "      <td>[0.359508547008547, 0.1205955334987593, 0.05010834236186349, 0.020174915523752734]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.023350</td>\n",
              "      <td>13104</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.222000</td>\n",
              "      <td>3.298485</td>\n",
              "      <td>0.105895</td>\n",
              "      <td>[0.4059772764696196, 0.15630614444843693, 0.07372998616327338, 0.033391915641476276]</td>\n",
              "      <td>0.947189</td>\n",
              "      <td>0.948536</td>\n",
              "      <td>12146</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.979100</td>\n",
              "      <td>3.054304</td>\n",
              "      <td>0.130490</td>\n",
              "      <td>[0.4211469534050179, 0.17859560067681896, 0.08902461595409958, 0.04330065359477124]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.002265</td>\n",
              "      <td>12834</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.724300</td>\n",
              "      <td>2.908994</td>\n",
              "      <td>0.152053</td>\n",
              "      <td>[0.4480133238163217, 0.20172488141440276, 0.10849636140251394, 0.058011915961116337]</td>\n",
              "      <td>0.984576</td>\n",
              "      <td>0.984693</td>\n",
              "      <td>12609</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.508000</td>\n",
              "      <td>2.733187</td>\n",
              "      <td>0.174331</td>\n",
              "      <td>[0.48776035183802174, 0.23339675636495424, 0.13469021251122418, 0.07736707736707736]</td>\n",
              "      <td>0.939350</td>\n",
              "      <td>0.941117</td>\n",
              "      <td>12051</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.341300</td>\n",
              "      <td>2.616960</td>\n",
              "      <td>0.183920</td>\n",
              "      <td>[0.49630651838623263, 0.24449358690844758, 0.14051112622680012, 0.07858143796485934]</td>\n",
              "      <td>0.961317</td>\n",
              "      <td>0.962046</td>\n",
              "      <td>12319</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.184000</td>\n",
              "      <td>2.521735</td>\n",
              "      <td>0.201474</td>\n",
              "      <td>[0.5165319617927994, 0.26550956831330663, 0.15771450934350847, 0.09134354295644619]</td>\n",
              "      <td>0.955623</td>\n",
              "      <td>0.956579</td>\n",
              "      <td>12249</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.033100</td>\n",
              "      <td>2.433972</td>\n",
              "      <td>0.214494</td>\n",
              "      <td>[0.5283432000648771, 0.2796677564725634, 0.16849461321945064, 0.09914953170416622]</td>\n",
              "      <td>0.962290</td>\n",
              "      <td>0.962983</td>\n",
              "      <td>12331</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.903400</td>\n",
              "      <td>2.380589</td>\n",
              "      <td>0.222451</td>\n",
              "      <td>[0.5332795482049213, 0.2872331078112644, 0.17468891675508827, 0.10445846252539293]</td>\n",
              "      <td>0.967463</td>\n",
              "      <td>0.967981</td>\n",
              "      <td>12395</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.794200</td>\n",
              "      <td>2.326355</td>\n",
              "      <td>0.231518</td>\n",
              "      <td>[0.5370519857927026, 0.29505890627747494, 0.18359073359073358, 0.11298951423068693]</td>\n",
              "      <td>0.966899</td>\n",
              "      <td>0.967435</td>\n",
              "      <td>12388</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.681100</td>\n",
              "      <td>2.300878</td>\n",
              "      <td>0.237071</td>\n",
              "      <td>[0.5541790551701354, 0.3085451595457004, 0.1941468253968254, 0.11978821972203839]</td>\n",
              "      <td>0.944060</td>\n",
              "      <td>0.945568</td>\n",
              "      <td>12108</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.584500</td>\n",
              "      <td>2.271592</td>\n",
              "      <td>0.252636</td>\n",
              "      <td>[0.565761316872428, 0.3239044540229885, 0.20845682671408813, 0.13230127360562144]</td>\n",
              "      <td>0.947518</td>\n",
              "      <td>0.948848</td>\n",
              "      <td>12150</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.508100</td>\n",
              "      <td>2.244786</td>\n",
              "      <td>0.253289</td>\n",
              "      <td>[0.5616684352297772, 0.323484915902821, 0.20727770713097918, 0.13095884460853513]</td>\n",
              "      <td>0.955786</td>\n",
              "      <td>0.956736</td>\n",
              "      <td>12251</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.436500</td>\n",
              "      <td>2.242780</td>\n",
              "      <td>0.251585</td>\n",
              "      <td>[0.5623409669211196, 0.3219625749843316, 0.20640078778926638, 0.13149546001531562]</td>\n",
              "      <td>0.950227</td>\n",
              "      <td>0.951425</td>\n",
              "      <td>12183</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.365800</td>\n",
              "      <td>2.229911</td>\n",
              "      <td>0.255804</td>\n",
              "      <td>[0.5691339625765856, 0.3289949385394071, 0.21303482587064676, 0.13656485170429394]</td>\n",
              "      <td>0.941584</td>\n",
              "      <td>0.943225</td>\n",
              "      <td>12078</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.315600</td>\n",
              "      <td>2.225173</td>\n",
              "      <td>0.259291</td>\n",
              "      <td>[0.5705824284304047, 0.3314485729671513, 0.21455371248025276, 0.13791968400263332]</td>\n",
              "      <td>0.948011</td>\n",
              "      <td>0.949317</td>\n",
              "      <td>12156</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.278100</td>\n",
              "      <td>2.221322</td>\n",
              "      <td>0.261519</td>\n",
              "      <td>[0.5714872637633525, 0.33309429903191107, 0.21642674028791165, 0.13988388651550004]</td>\n",
              "      <td>0.949160</td>\n",
              "      <td>0.950410</td>\n",
              "      <td>12170</td>\n",
              "      <td>12805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=36260, training_loss=2.4686950254361406, metrics={'train_runtime': 3507.058, 'train_samples_per_second': 165.381, 'train_steps_per_second': 10.339, 'total_flos': 1.966105165824e+16, 'train_loss': 2.4686950254361406, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.pad_token_id)\n",
        "print(tokenizer.eos_token)\n",
        "print(model.config.eos_token_id)"
      ],
      "metadata": {
        "id": "WlMNnNjBj3vQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cacd37e-86d8-4f17-c6c7-18aecfe2ca40"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58100\n",
            "</s>\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    input_ids = tokenized_datasets[\"validation\"][\"input_ids\"][i]\n",
        "    labels = tokenized_datasets[\"validation\"][\"labels\"][i]\n",
        "    print(\"Input:\", tokenizer.decode(input_ids, skip_special_tokens=True))\n",
        "    print(\"Label:\", tokenizer.decode(labels, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "qlXS3us9X5c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116d6767-4e5b-442c-8f8a-85dff58ac233"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: A group of men are loading cotton onto a truck\n",
            "Label: Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen\n",
            "Input: A man sleeping in a green room on a couch.\n",
            "Label: Ein Mann schläft in einem grünen Raum auf einem Sofa.\n",
            "Input: A boy wearing headphones sits on a woman's shoulders.\n",
            "Label: Ein Junge mit Kopfhörern sitzt auf den Schultern einer Frau.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    input_ids = tokenized_datasets[\"test\"][\"input_ids\"][i]\n",
        "    label_ids = tokenized_datasets[\"test\"][\"labels\"][i]\n",
        "\n",
        "    input_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "    label_text = tokenizer.decode(label_ids, skip_special_tokens=True)\n",
        "    output_ids = model.generate(torch.tensor([input_ids]).to(model.device), max_length=128)[0]\n",
        "    output_text = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "\n",
        "    print(f\"[EN] {input_text}\")\n",
        "    print(f\"[GT] {label_text}\")\n",
        "    print(f\"[PR] {output_text}\\n\")"
      ],
      "metadata": {
        "id": "m2q18dcih0BZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee55d1e0-e255-4c29-b7bb-3bc17cb3494f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EN] A man in an orange hat starring at something.\n",
            "[GT] Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\n",
            "[PR] Ein Mann mit einem orangefarbenen Hut starrt etwas.\n",
            "\n",
            "[EN] A Boston Terrier is running on lush green grass in front of a white fence.\n",
            "[GT] Ein Boston Terrier läuft über saftig-grünes Gras vor einem weißen Zaun.\n",
            "[PR] Ein Fischer läuft vor einem weißen Zaun in der Nähe eines weißen Zauns.\n",
            "\n",
            "[EN] A girl in karate uniform breaking a stick with a front kick.\n",
            "[GT] Ein Mädchen in einem Karateanzug bricht ein Brett mit einem Tritt.\n",
            "[PR] Ein Mädchen in Karateanzug macht einen Stock vor einem Waschbecken.\n",
            "\n",
            "[EN] Five people wearing winter jackets and helmets stand in the snow, with snowmobiles in the background.\n",
            "[GT] Fünf Leute in Winterjacken und mit Helmen stehen im Schnee mit Schneemobilen im Hintergrund.\n",
            "[PR] Fünf Personen in orangefarbenen Westen und mit Helmen stehen im Schnee, im Hintergrund ist ein Schneeer.\n",
            "\n",
            "[EN] People are fixing the roof of a house.\n",
            "[GT] Leute Reparieren das Dach eines Hauses.\n",
            "[PR] Menschen halten die Dach eines Hauses.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4_qo7JVhr-5"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}